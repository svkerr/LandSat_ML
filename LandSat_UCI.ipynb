{
 "metadata": {
  "name": "LandSat_UCI"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "LandSat Data Set obtained from University California Irvine"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using this data set, we will use SVM techniques to classify the type of imagery.\n",
      "\n",
      "Descriptions of this data set can be found in the file titled: `sat.doc`.\n",
      "\n",
      "Both the training and test files are space separated\n",
      "\n",
      "Action: rescale `lsat_data` and measure performance (speed, precision, accuracy) for differences..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn as sk\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the data sets and check their sizes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsat = np.loadtxt('sat.trn.txt', delimiter = ' ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsat_tst = np.loadtxt('sat.tst.txt', delimiter = ' ')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print type(lsat)\n",
      "print lsat.shape\n",
      "print lsat_tst.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n",
        "(4435, 37)\n",
        "(2000, 37)\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsat_target = lsat[:,36]\n",
      "lsat_data = lsat[:,0:35]\n",
      "print lsat_target.shape\n",
      "print lsat_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4435,)\n",
        "(4435, 35)\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ensure i captured just the last column for the target values:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.max(lsat_target)\n",
      "print np.min(lsat_target)\n",
      "print np.mean(lsat_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.0\n",
        "1.0\n",
        "3.65028184893\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The SVC implementation (of an SVM) has various parameters. The most relevant is kernel, which defines the classifier's kernel (think of the kernel functions as different similarity measures between instances). The default SVC kernel is the rbf kernel, which allows us to model nonlinear problems. We will start with the simplest one: linear"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.svm import SVC\n",
      "svc_1 = SVC(kernel='linear')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,X_test, y_train, y_test = train_test_split(lsat_data, lsat_target, test_size = 0.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape\n",
      "print y_train.shape\n",
      "print y_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3326, 35)\n",
        "(1109, 35)\n",
        "(3326,)\n",
        "(1109,)\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, KFold\n",
      "from scipy.stats import sem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function to evaluate K-fold cross-validation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluate_cross_validation(clf, X, y, K):\n",
      "    #create a k-fold cross validation iterator\n",
      "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
      "    # by default, the score used is the one returned by score method of estimator (`accuracy`)\n",
      "    scores = cross_val_score(clf, X, y, cv=cv)\n",
      "    print scores\n",
      "    print(\"Mean score: {0:.3f} (+/- {1:.3f})\").format(np.mean(scores),sem(scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_cross_validation(svc_1, X_train, y_train, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.87067669  0.86165414  0.87218045  0.86466165  0.84984985]\n",
        "Mean score: 0.864 (+/- 0.004)\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will also define a function to perform training on the training set and evaluate the performance on the testing set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
      "    clf.fit(X_train,y_train)\n",
      "    print \"Accuracy on training set:\"\n",
      "    print clf.score(X_train, y_train)\n",
      "    print \"Accuracy on testing set:\"\n",
      "    print clf.score(X_test, y_test)\n",
      "    \n",
      "    y_pred = clf.predict(X_test)\n",
      "    \n",
      "    print \"Classification Report:\"\n",
      "    print metrics.classification_report(y_test, y_pred)\n",
      "    print \"Confusion Matrix\"\n",
      "    print metrics.confusion_matrix(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time train_and_evaluate(svc_1, X_train, X_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy on training set:\n",
        "0.90288634997"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on testing set:\n",
        "0.863841298467\n",
        "Classification Report:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.97      0.98      0.97       278\n",
        "          2       0.93      0.94      0.94       121\n",
        "          3       0.88      0.93      0.90       235\n",
        "          4       0.50      0.40      0.44        95\n",
        "          5       0.78      0.78      0.78       113\n",
        "          7       0.85      0.85      0.85       267\n",
        "\n",
        "avg / total       0.86      0.86      0.86      1109\n",
        "\n",
        "Confusion Matrix\n",
        "[[272   0   2   0   4   0]\n",
        " [  1 114   0   0   6   0]\n",
        " [  2   0 219  13   0   1]\n",
        " [  1   2  24  38   2  28]\n",
        " [  5   4   1   4  88  11]\n",
        " [  0   2   4  21  13 227]]\n",
        "CPU times: user 14.09 s, sys: 0.02 s, total: 14.11 s\n",
        "Wall time: 14.12 s\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's repeat the above, but this time with a normalized `lsat_data` data set. This is called `feature scaling`. For each feature, calculate the average, subtract the mean value from the feature value, and divide the result by their standard deviation. After scaling, each feature will have a zero average, with a standard dev of one. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,X_test, y_train, y_test = train_test_split(lsat_data, lsat_target, test_size = 0.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = preprocessing.StandardScaler().fit(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = scaler.transform(X_train)\n",
      "X_test = scaler.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evaluate_cross_validation(svc_1, X_train, y_train, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.87067669  0.86766917  0.87669173  0.86917293  0.86186186]\n",
        "Mean score: 0.869 (+/- 0.002)\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time train_and_evaluate(svc_1, X_train, X_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy on training set:\n",
        "0.893866506314"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on testing set:\n",
        "0.862939585212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Classification Report:\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          1       0.96      0.97      0.97       278\n",
        "          2       0.95      0.95      0.95       121\n",
        "          3       0.87      0.95      0.91       235\n",
        "          4       0.52      0.40      0.45        95\n",
        "          5       0.76      0.79      0.77       113\n",
        "          7       0.84      0.83      0.84       267\n",
        "\n",
        "avg / total       0.86      0.86      0.86      1109\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Confusion Matrix\n",
        "[[270   0   4   0   4   0]\n",
        " [  1 115   0   0   5   0]\n",
        " [  0   0 223  12   0   0]\n",
        " [  1   2  23  38   2  29]\n",
        " [  8   2   0   2  89  12]\n",
        " [  0   2   5  21  17 222]]\n",
        "CPU times: user 0.48 s, sys: 0.00 s, total: 0.48 s\n",
        "Wall time: 0.49 s\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "array([ 0.10216372, -0.22207389, -1.21673231, -1.048497  , -0.10143943,\n",
        "       -0.38405076, -1.45304076, -1.26074482, -0.08559817, -0.67659275,\n",
        "       -1.68024466, -1.41201414, -0.17772433, -0.51919996, -1.52141711,\n",
        "       -1.31596378, -0.45885966, -0.68254707, -1.50983753, -1.3196504 ,\n",
        "       -0.45003186, -0.67274511, -1.49884229, -1.31074249, -0.46382005,\n",
        "       -0.73245601, -1.57755887, -1.47308922, -0.45719771, -0.7294942 ,\n",
        "       -1.81971682, -1.47968819, -0.21999448, -0.36952741, -1.39996234])"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsat_data[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "array([  92.,  115.,  120.,   94.,   84.,  102.,  106.,   79.,   84.,\n",
        "        102.,  102.,   83.,  101.,  126.,  133.,  103.,   92.,  112.,\n",
        "        118.,   85.,   84.,  103.,  104.,   81.,  102.,  126.,  134.,\n",
        "        104.,   88.,  121.,  128.,  100.,   84.,  107.,  113.])"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.max(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "157.0"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.min(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "27.0"
       ]
      }
     ],
     "prompt_number": 88
    }
   ],
   "metadata": {}
  }
 ]
}